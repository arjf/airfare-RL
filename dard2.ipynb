{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH=\"/kaggle/input/airfares-enhanced/Enhanced_Dataset_with_Dynamic_Pricing.csv\"\n",
    "PATH=\"airfares-enhanced.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>...</th>\n",
       "      <th>travel_date</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>seasonality</th>\n",
       "      <th>is_festival</th>\n",
       "      <th>demand_index</th>\n",
       "      <th>competitor_price</th>\n",
       "      <th>seats_left</th>\n",
       "      <th>adjusted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8709</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>zero</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6004.29</td>\n",
       "      <td>5</td>\n",
       "      <td>8598.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8157</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.33</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6057.64</td>\n",
       "      <td>5</td>\n",
       "      <td>8598.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AirAsia</td>\n",
       "      <td>I5-764</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6392.52</td>\n",
       "      <td>5</td>\n",
       "      <td>8603.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-995</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5908.67</td>\n",
       "      <td>5</td>\n",
       "      <td>8006.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-963</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.33</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5623.71</td>\n",
       "      <td>5</td>\n",
       "      <td>8006.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   airline   flight source_city departure_time stops  \\\n",
       "0           0  SpiceJet  SG-8709       Delhi        Evening  zero   \n",
       "1           1  SpiceJet  SG-8157       Delhi  Early_Morning  zero   \n",
       "2           2   AirAsia   I5-764       Delhi  Early_Morning  zero   \n",
       "3           3   Vistara   UK-995       Delhi        Morning  zero   \n",
       "4           4   Vistara   UK-963       Delhi        Morning  zero   \n",
       "\n",
       "    arrival_time destination_city    class  duration  ...  travel_date  month  \\\n",
       "0          Night           Mumbai  Economy      2.17  ...   2023-01-02      1   \n",
       "1        Morning           Mumbai  Economy      2.33  ...   2023-01-02      1   \n",
       "2  Early_Morning           Mumbai  Economy      2.17  ...   2023-01-02      1   \n",
       "3      Afternoon           Mumbai  Economy      2.25  ...   2023-01-02      1   \n",
       "4        Morning           Mumbai  Economy      2.33  ...   2023-01-02      1   \n",
       "\n",
       "  day_of_week  is_weekend  seasonality  is_festival demand_index  \\\n",
       "0           0           0       Medium            0          1.0   \n",
       "1           0           0       Medium            0          1.0   \n",
       "2           0           0       Medium            0          1.0   \n",
       "3           0           0       Medium            0          1.0   \n",
       "4           0           0       Medium            0          1.0   \n",
       "\n",
       "   competitor_price  seats_left  adjusted_price  \n",
       "0           6004.29           5         8598.78  \n",
       "1           6057.64           5         8598.78  \n",
       "2           6392.52           5         8603.11  \n",
       "3           5908.67           5         8006.17  \n",
       "4           5623.71           5         8006.17  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(PATH)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import gym\n",
    "from gym import spaces\n",
    "from sbx import PPO, TD3, SAC\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32938/3626008834.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PATH)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Categorical Encoding\n",
    "categorical_cols = ['flight','airline','source_city','departure_time','stops',\n",
    "                   'arrival_time','destination_city','class','seasonality']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "# Handle dates\n",
    "df['travel_date']=pd.to_datetime(df['travel_date'])\n",
    "period = 365.25\n",
    "df['day_sin'] = np.sin(df['travel_date'].dt.day * (2 * np.pi / period))\n",
    "df['day_cos'] = np.cos(df['travel_date'].dt.day * (2 * np.pi / period))\n",
    "df['day_of_month'] = df['travel_date'].dt.month\n",
    "df['week_of_year'] = df['travel_date'].dt.isocalendar().week\n",
    "df=df.drop(\"travel_date\", axis=1)\n",
    "\n",
    "target = 'price'\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "num_features = ['duration','demand_index','competitor_price',\n",
    "               'seats_left','adjusted_price']\n",
    "df[num_features] = scaler.fit_transform(df[num_features])\n",
    "\n",
    "# For the environment, save min and max price for scaling actions\n",
    "min_price = df[target].min()\n",
    "max_price = df[target].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 int64\n",
      "airline int8\n",
      "flight int16\n",
      "source_city int8\n",
      "departure_time int8\n",
      "stops int8\n",
      "arrival_time int8\n",
      "destination_city int8\n",
      "class int8\n",
      "duration float64\n",
      "days_left int64\n",
      "price int64\n",
      "month int64\n",
      "day_of_week int64\n",
      "is_weekend int64\n",
      "seasonality int8\n",
      "is_festival int64\n",
      "demand_index float64\n",
      "competitor_price float64\n",
      "seats_left float64\n",
      "adjusted_price float64\n",
      "day_sin float64\n",
      "day_cos float64\n",
      "day_of_month int32\n",
      "week_of_year UInt32\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col, df[col].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Airfare Prediction Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AirfarePricingEnv(gym.Env):\n",
    "    def __init__(self, data, min_price, max_price):\n",
    "        super().__init__()\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.current_idx = 0\n",
    "        self.min_price = min_price\n",
    "        self.max_price = max_price\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)  # normalized price\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=1, shape=(data.shape[1] - 1,), dtype=np.float32\n",
    "        )\n",
    "        # Example coefficients for the demand model (customize as needed)\n",
    "        self.beta = np.random.uniform(-1, 1, size=(data.shape[1] - 1))\n",
    "        self.gamma = -2.0  # price sensitivity\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_idx = 0\n",
    "        return self.data.iloc[self.current_idx, :-1].values.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        price = float(action[0]) * (self.max_price - self.min_price) + self.min_price\n",
    "        X = self.data.iloc[self.current_idx, :-1].values\n",
    "\n",
    "        # exponent_value = -np.dot(self.beta, X) - self.gamma * price\n",
    "        # if abs(exponent_value) > 700:\n",
    "        #     print(f\"Large exponent detected: {exponent_value}\")\n",
    "        #     print(f\"Beta max/min: {np.max(self.beta)}/{np.min(self.beta)}\")\n",
    "        #     print(f\"X max/min: {np.max(X)}/{np.min(X)}\")\n",
    "        #     print(f\"Price: {price}\")\n",
    "        \n",
    "        # Simulate purchase probability (logistic demand model)\n",
    "        prob_purchase = expit(np.dot(self.beta, X) + self.gamma * price)\n",
    "        #prob_purchase = 1 / (1 + np.exp(-np.dot(self.beta, X) - self.gamma * price))\n",
    "        reward = price * prob_purchase\n",
    "        self.current_idx += 1\n",
    "        done = self.current_idx >= len(self.data)\n",
    "        next_state = (\n",
    "            self.data.iloc[self.current_idx, :-1].values.astype(np.float32)\n",
    "            if not done\n",
    "            else np.zeros_like(X, dtype=np.float32)\n",
    "        )\n",
    "        return next_state, reward, done, {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Metrics Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self, model_name):\n",
    "        self.rewards = []\n",
    "        self.model_name = model_name\n",
    "        self.metrics_dir = f'metrics/{model_name}'\n",
    "        os.makedirs(self.metrics_dir, exist_ok=True)\n",
    "    \n",
    "    def log_reward(self, reward):\n",
    "        self.rewards.append(reward)\n",
    "    \n",
    "    def save_and_plot(self):\n",
    "        rewards = np.array(self.rewards)\n",
    "        np.save(f'{self.metrics_dir}/rewards.npy', rewards)\n",
    "        window = min(100, len(rewards))\n",
    "        moving_avg = np.convolve(rewards, np.ones(window) / window, mode='valid')\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(moving_avg)\n",
    "        plt.title(f'Moving Average Reward - {self.model_name}')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Reward')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{self.metrics_dir}/reward_curve.png')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model_class, model_name, env, total_timesteps=100_000):\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model = model_class(\n",
    "        'MlpPolicy', \n",
    "        env, \n",
    "        verbose=1,\n",
    "        n_steps=512,\n",
    "        batch_size=64,\n",
    "        n_epochs=10\n",
    "    )\n",
    "    model.learn(total_timesteps=total_timesteps, progress_bar=True)\n",
    "    model.save(f'{model_name}_airfare')\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    metrics = Metrics(model_name)\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        metrics.log_reward(reward)\n",
    "    metrics.save_and_plot()\n",
    "    print(f\"{model_name} metrics saved in metrics/{model_name}/\")\n",
    "    return metrics\n",
    "\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajdj/clones/airfare-2/.conda/lib/python3.12/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ppo...\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajdj/clones/airfare-2/.conda/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 514  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 3    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013157856 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | -1.31e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.88e+07    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 8.34e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 411          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019792803 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.0008       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.28e+07     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.000889    |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 2.57e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 419          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035233637 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.00259      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.34e+05     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000714    |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 2.06e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 416          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018463148 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.00826      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.35e+05     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    std                  | 0.964        |\n",
      "|    value_loss           | 1.03e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 413       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 29        |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0012821 |\n",
      "|    clip_fraction        | 0.000488  |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.38     |\n",
      "|    explained_variance   | 0.00366   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.47e+06  |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -0.000114 |\n",
      "|    std                  | 0.962     |\n",
      "|    value_loss           | 8.58e+06  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 415         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003249941 |\n",
      "|    clip_fraction        | 0.00659     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 2.38e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+07    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 3.48e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 417          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034911167 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.0162       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.36e+05     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    std                  | 0.951        |\n",
      "|    value_loss           | 1.24e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018756721 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.0363      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.12e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | 0.00138     |\n",
      "|    std                  | 0.949       |\n",
      "|    value_loss           | 4.77e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 421          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010204786 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.083        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.86e+03     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | 0.000118     |\n",
      "|    std                  | 0.942        |\n",
      "|    value_loss           | 9.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 421          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003119678 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.0107       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.08e+05     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | 0.000134     |\n",
      "|    std                  | 0.945        |\n",
      "|    value_loss           | 2.07e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 419          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039029834 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.00294      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.5e+05      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    std                  | 0.943        |\n",
      "|    value_loss           | 1.65e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 413          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007985836 |\n",
      "|    clip_fraction        | 0.0337       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.0752       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.74e+03     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.000447    |\n",
      "|    std                  | 0.948        |\n",
      "|    value_loss           | 1.4e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 410          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028629107 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.0736       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 91.1         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | 0.000798     |\n",
      "|    std                  | 0.919        |\n",
      "|    value_loss           | 4.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 410          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023297996 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | -3.38        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -3.96e-05    |\n",
      "|    std                  | 0.896        |\n",
      "|    value_loss           | 28.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 409          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036118997 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.0216       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+05     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.000707    |\n",
      "|    std                  | 0.896        |\n",
      "|    value_loss           | 4.15e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 409          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075978185 |\n",
      "|    clip_fraction        | 0.0704       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | -8.32        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.775        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | 0.000694     |\n",
      "|    std                  | 0.898        |\n",
      "|    value_loss           | 9.13         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 408          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023812912 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | -5.09        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.122        |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    std                  | 0.918        |\n",
      "|    value_loss           | 1.77         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 408          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019871923 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.0242       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.94e+04     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | 0.000804     |\n",
      "|    std                  | 0.919        |\n",
      "|    value_loss           | 1.03e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 408         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000600085 |\n",
      "|    clip_fraction        | 0.00288     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.0567      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.51e+03    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.000207   |\n",
      "|    std                  | 0.919       |\n",
      "|    value_loss           | 1.44e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 409          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029714764 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | -16.1        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.513        |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    std                  | 0.895        |\n",
      "|    value_loss           | 5.26         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 409          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029872032 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | -17.5        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.173        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000349    |\n",
      "|    std                  | 0.889        |\n",
      "|    value_loss           | 4.32         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 411           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 114           |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019723675 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.3          |\n",
      "|    explained_variance   | 0.0719        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.36e+04      |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.000531     |\n",
      "|    std                  | 0.889         |\n",
      "|    value_loss           | 4.19e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 412          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006029237 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | -1.28        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.34         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | 0.000489     |\n",
      "|    std                  | 0.89         |\n",
      "|    value_loss           | 34.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 413         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005220201 |\n",
      "|    clip_fraction        | 0.0303      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -7.07       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0201      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    std                  | 0.893       |\n",
      "|    value_loss           | 1.99        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 413          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029041306 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | -11.1        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0135       |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | 0.00143      |\n",
      "|    std                  | 0.895        |\n",
      "|    value_loss           | 1.36         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 414         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003656707 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | -1.79       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.547       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    std                  | 0.896       |\n",
      "|    value_loss           | 4.05        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 415          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059839427 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | -3.36        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0739       |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | 0.00161      |\n",
      "|    std                  | 0.895        |\n",
      "|    value_loss           | 2.42         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 415         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009275701 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -3.53       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0177      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 0.00121     |\n",
      "|    std                  | 0.919       |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 416        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01063046 |\n",
      "|    clip_fraction        | 0.095      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.33      |\n",
      "|    explained_variance   | -0.36      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.000363   |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | 0.00164    |\n",
      "|    std                  | 0.915      |\n",
      "|    value_loss           | 0.0904     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 416          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029254965 |\n",
      "|    clip_fraction        | 0.0491       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | -0.202       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00803      |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | 0.000699     |\n",
      "|    std                  | 0.912        |\n",
      "|    value_loss           | 0.0529       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016249686 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -7.03       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00952     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.00116     |\n",
      "|    std                  | 0.933       |\n",
      "|    value_loss           | 0.0953      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 417          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090968665 |\n",
      "|    clip_fraction        | 0.0836       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -0.118       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00312      |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | 0.00115      |\n",
      "|    std                  | 0.929        |\n",
      "|    value_loss           | 0.0204       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 417          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014566884 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00464     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | 0.000785     |\n",
      "|    std                  | 0.908        |\n",
      "|    value_loss           | 0.0137       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 418          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035792524 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | -0.0845      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000708    |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000592    |\n",
      "|    std                  | 0.902        |\n",
      "|    value_loss           | 0.0121       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 419          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 175          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033955951 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | -1.23        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00842     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.000803    |\n",
      "|    std                  | 0.906        |\n",
      "|    value_loss           | 0.00711      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 419         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009011592 |\n",
      "|    clip_fraction        | 0.0326      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -0.00266    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.017       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.000107   |\n",
      "|    std                  | 0.874       |\n",
      "|    value_loss           | 0.00435     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 420        |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 185        |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00842697 |\n",
      "|    clip_fraction        | 0.0943     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0105    |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.00196   |\n",
      "|    std                  | 0.868      |\n",
      "|    value_loss           | 0.00274    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 420          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 189          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028554033 |\n",
      "|    clip_fraction        | 0.0386       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | -5.72        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0014      |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    std                  | 0.851        |\n",
      "|    value_loss           | 0.00339      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 421         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007065934 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | -0.957      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00153    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.00117     |\n",
      "|    std                  | 0.841       |\n",
      "|    value_loss           | 0.00197     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 422          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014517051 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | -0.000427    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00455     |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | 0.000351     |\n",
      "|    std                  | 0.826        |\n",
      "|    value_loss           | 0.00119      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 422           |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 203           |\n",
      "|    total_timesteps      | 86016         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040873402 |\n",
      "|    clip_fraction        | 0.0383        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.23         |\n",
      "|    explained_variance   | -0.00164      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000463     |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | -0.000188     |\n",
      "|    std                  | 0.825         |\n",
      "|    value_loss           | 0.00105       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 422         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004075778 |\n",
      "|    clip_fraction        | 0.0462      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | -9.26       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0247      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | 0.00189     |\n",
      "|    std                  | 0.816       |\n",
      "|    value_loss           | 0.00119     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 421         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002762748 |\n",
      "|    clip_fraction        | 0.0482      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00154     |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00165     |\n",
      "|    std                  | 0.797       |\n",
      "|    value_loss           | 0.000733    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 421          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057790233 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00101     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -4.79e-05    |\n",
      "|    std                  | 0.771        |\n",
      "|    value_loss           | 0.00044      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 421          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032204278 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00641     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | 0.000313     |\n",
      "|    std                  | 0.763        |\n",
      "|    value_loss           | 0.000176     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 421          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 228          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022409963 |\n",
      "|    clip_fraction        | 0.0875       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | -0.025       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.013       |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | 0.00224      |\n",
      "|    std                  | 0.741        |\n",
      "|    value_loss           | 0.000177     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 421         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014798949 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | -25.5       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00391    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    std                  | 0.732       |\n",
      "|    value_loss           | 0.00108     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 421          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028368342 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00662     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.000137    |\n",
      "|    std                  | 0.698        |\n",
      "|    value_loss           | 0.000172     |\n",
      "------------------------------------------\n",
      "Evaluating ppo...\n",
      "ppo metrics saved in metrics/ppo/\n",
      "Training td3...\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajdj/clones/airfare-2/.conda/lib/python3.12/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "# Prepare the environment\n",
    "#env = AirfarePricingEnv(df, min_price, max_price)\n",
    "env = make_vec_env(AirfarePricingEnv, n_envs=16, env_kwargs={\n",
    "    'data': df, \n",
    "    'min_price': min_price, \n",
    "    'max_price': max_price\n",
    "})\n",
    "# Train and evaluate each model\n",
    "model_classes = {'ppo': PPO, 'td3': TD3, 'sac': SAC}\n",
    "all_metrics = {}\n",
    "for name, cls in model_classes.items():\n",
    "    # Re-instantiate the environment for each model for a fresh start\n",
    "    env = AirfarePricingEnv(df, min_price, max_price)\n",
    "    metrics = train_and_evaluate(cls, name, env)\n",
    "    all_metrics[name] = metrics\n",
    "\n",
    "# Optionally, plot all moving averages for comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, metrics in all_metrics.items():\n",
    "    rewards = np.array(metrics.rewards)\n",
    "    window = min(100, len(rewards))\n",
    "    moving_avg = np.convolve(rewards, np.ones(window) / window, mode='valid')\n",
    "    plt.plot(moving_avg, label=name.upper())\n",
    "plt.title('Moving Average Reward Comparison')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('metrics/reward_comparison.png')\n",
    "plt.close()\n",
    "print(\"All done! Metrics and models saved.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7203097,
     "sourceId": 11490974,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
